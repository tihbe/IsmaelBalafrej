{
  "hash": "5875cfc784a834a791351a3988eb8937",
  "result": {
    "markdown": "---\ntitle: \"Selection of a timestep for SNN simulation\"\ndescription: \"What is the proper timestep to select when simulating a spiking neural network ? The answer is, of course, it depends. Although, I think the usual assumption is incorrect when using leaky-integrate-and-fire neurons.\"\ndate: \"3/19/2023\"\ndraft: true\ncategories:\n  - SNN\n  - LIF\n---\n\n# Context\n\nI recently saw [this tweet](https://twitter.com/neuralreckoning/status/1580161403415330816) by Dan Goodman. In a quick experiment, they show that using a large timestep $\\delta t$ during the simulation of a LIF neuron is detrimental to its behavior. Indeed, the output spiking rate of a LIF neuron with a Poisson spike input decreases when the timestep increases. It already fails at 1 ms, which is somewhat a standard size for timesteps in the CS-oriented community. Even worse, at $\\delta t=10$ ms, the neuron doesn't even spike anymore. \n\nOf course, there is a direct relationship between the choice of $\\delta t$, and real-world simulation duration (or wall-clock time). Ideally, we would all be using a very large $\\delta t$ for our simulation. As [Guillaume Bellec](https://twitter.com/BellecGuill/status/1580440789217595394) pointed out, there might not even be any advantage in a machine learning setting to using a small $\\delta t$.\n\n\n# Step 1: Recreating the simulation\n\nLet's define a simple experiment to replicate the behavior described in the tweet. We will create 100 LIF neurons, being simulated by 100 poisson spike trains sampled at 5 Hz for 4 seconds. The LIF's time constant is $\\tau=10$ ms. The weights between the 100 inputs and 100 output neurons are randomly sampled from a normal distribution $\\mathcal{N}(0.5, 1)$.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Configuration\nnp.random.seed(0x1B)\nduration = 4 # seconds\ntau = 0.010\nthresh = 1\nnb_inputs = 100\nnb_outputs = 100\ninput_rate = 5\nweights = np.random.randn(nb_outputs, nb_inputs) + 0.5 * thresh\ndts = np.logspace(-5, -1.5, 10) # in seconds\n\n# Simulation\nfig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\nspike_rates = np.zeros((len(dts), nb_outputs)) # output\nfor i, dt in enumerate(dts):\n    time = np.arange(0, duration, dt)\n    u = np.zeros(nb_outputs)\n    _exp = np.exp(-dt/tau)\n    input_spikes = np.random.poisson(lam=input_rate*dt, size=(len(time), nb_inputs))\n    weighted_input_spikes = input_spikes @ weights.T\n    spike_count = 0\n\n    for j, t in enumerate(time):\n        u = _exp * u + weighted_input_spikes[j]\n        spikes = u > thresh\n        spike_count += spikes\n        u[spikes] = 0 # reset\n    spike_rates[i] += spike_count / duration\nax.errorbar(dts*1000, spike_rates.mean(axis=1), yerr=spike_rates.std(axis=1), capsize=5,)\nax.set_xscale(\"log\")\nax.set_xlabel(\"dt [ms]\")\nax.set_ylabel(\"Output firing rate [sp/s]\");\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=566 height=374}\n:::\n:::\n\n\nWe arrive at a similar looking plot, where the output spiking frequency is going down near $\\delta t=1$ms. \n\n\n\n\n\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0x1B)\nduration = 10 # seconds\ntau = 0.010\nthresh = 1\nnb_inputs = 100\nnb_outputs = 100\nweights = np.random.randn(nb_outputs, nb_inputs) + 0.5 * thresh\n\nnb_samples = 5 # Samples per dt\nduration = 5 # seconds\ndts = np.logspace(-5, -2, 10) # in seconds\n\nfig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\neffective_spike_rates = np.zeros_like(dts)\nspike_rates = np.linspace(20, 200, 5)\n\nfor in_spike_rate in spike_rates:\n    effective_spike_rates = np.zeros_like(dts)\n    for i, dt in enumerate(dts):\n        input_spikes = np.random.poisson(lam=in_spike_rate*dt, size=int(duration / dt))\n        input_spikes = np.clip(input_spikes, 0, 1) # This is the limitation\n        \n        effective_spike_rates[i] += input_spikes.sum() / duration        \n    ax.plot(dts*1000, effective_spike_rates, label=f\"Input freq.: {in_spike_rate:.0f} Hz\")\n    \nax.set_ylabel(\"Measured output rate [Hz]\")\nax.set_xlabel(\"$\\\\delta t$ [ms]\")\nax.set_xscale(\"log\")\nax.legend(loc=\"lower left\");\n```\n\n\n\n\n\n```\nfor in_spike_rate in spike_rates:\n    P_failure = np.zeros_like(dts)\n    for i, dt in enumerate(dts):\n        P_failure[i] = 1-(np.exp(-in_spike_rate*dt) + np.exp(-in_spike_rate*dt)*((in_spike_rate*dt)))\n    ax[1].plot(dts*1000, P_failure, label=f\"Rate parameter: {in_spike_rate}Hz\")\nax[1].set_ylabel(\"Probability of missed event\")\nax[1].set_xlabel(\"dt [ms]\")\nax[1].set_xscale(\"log\")\nax[1].legend(loc=\"upper left\");\n```\n\n\n\n```\nfig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n\nfor refractory_period in [0.002, 0.02, 0.2]:\n    spike_rates = np.zeros((len(dts), nb_outputs)) # output\n    for i, dt in enumerate(dts):\n        time = np.arange(0, duration, dt)\n        refrac_clk = int(refractory_period/dt)\n        u = np.zeros(nb_outputs)\n        refrac_cntr = np.zeros(nb_outputs, dtype=int)\n        _exp = np.exp(-dt/tau)\n        input_spikes = np.random.poisson(lam=input_rate*dt, size=(len(time), nb_inputs))\n        weighted_input_spikes = input_spikes @ weights.T\n        spike_count = 0\n\n        for j, t in enumerate(time):\n            refrac_cntr = np.maximum(refrac_cntr-1, 0)\n            non_refrac_neurons = refrac_cntr==0\n            u[non_refrac_neurons] = _exp * u[non_refrac_neurons] + weighted_input_spikes[j, non_refrac_neurons]\n            spikes = u > thresh\n            spike_count += spikes\n            refrac_cntr[spikes] += refrac_clk\n            u[spikes] = 0 # reset\n        spike_rates[i] += spike_count / duration\n    ax.errorbar(dts*1000, spike_rates.mean(axis=1), yerr=spike_rates.std(axis=1), capsize=5, label=f\"Refractory period: {1000*refractory_period:.0e}ms\")\n    ax.set_xscale(\"log\")\n    ax.set_xlabel(\"dt [ms]\")\n    ax.set_ylabel(\"Output firing rate [sp/s]\")\n    ax.legend(loc=\"lower left\")\nax.set_yscale(\"log\")\n```\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}