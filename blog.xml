<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Ismael Balafrej</title>
<link>https://tihbe.github.io/blog.html</link>
<atom:link href="https://tihbe.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Ismael Balafrej&#39;s personal Blog.</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Sun, 19 Mar 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Selection of a timestep for SNN simulation</title>
  <dc:creator>Ismael Balafrej</dc:creator>
  <link>https://tihbe.github.io/posts/2023-03-18-dt-vs-lif/index.html</link>
  <description><![CDATA[ 



<section id="context" class="level1">
<h1>Context</h1>
<p>I recently saw <a href="https://twitter.com/neuralreckoning/status/1580161403415330816">this tweet</a> by Dan Goodman. In a quick experiment, they show that using a large timestep <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> during the simulation of a LIF neuron is detrimental to its behavior. Indeed, the output spiking rate of a LIF neuron with a Poisson spike input decreases when the timestep increases. It already fails at 1 ms, which is somewhat a standard size for timesteps in the CS-oriented community. Even worse, at <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t=10"> ms, the neuron doesn’t even spike anymore.</p>
<p>Of course, there is a direct relationship between the choice of <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t">, and real-world simulation duration (or wall-clock time). Ideally, we would all be using a very large <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> for our simulation. As <a href="https://twitter.com/BellecGuill/status/1580440789217595394">Guillaume Bellec</a> pointed out, there might not even be any advantage in a machine learning setting to using a small <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t">. Instead of simply accepting the fact that one must use a small timestep, I was wondering why is this simulation failing, even when using an exact solver instead of Euler’s method. There should be a small distinction when the spike arrives at the beginning, or the end, of a clock cycles. We somewhat over or underestimate the membrane potential by <img src="https://latex.codecogs.com/png.latex?w%5Cexp(%5Cfrac%7B-%5Cdelta%20t%7D%7B%5Ctau%7D)"> depending on when the spike arrived during the clock period.</p>
</section>
<section id="recreating-the-simulation" class="level1">
<h1>Recreating the Simulation</h1>
<p>Let’s define a simple experiment to replicate the behavior described in the tweet. We will create 100 LIF neurons, being simulated by 100 Poisson spike trains sampled at 5 Hz for 4 seconds. The LIF’s time constant is <img src="https://latex.codecogs.com/png.latex?%5Ctau=10"> ms. The weights between the 100 inputs and 1000 output neurons are randomly sampled from a normal distribution <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BN%7D(0.1,%200.25)">. We then take the mean output firing rate of every output neuron, and the standard deviation as error bars.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Configuration</span></span>
<span id="cb1-5">np.random.seed(<span class="bn" style="color: #AD0000;">0x1B</span>)</span>
<span id="cb1-6">duration <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span> <span class="co" style="color: #5E5E5E;"># seconds</span></span>
<span id="cb1-7">tau <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.010</span></span>
<span id="cb1-8">thresh <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb1-9">nb_inputs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span></span>
<span id="cb1-10">nb_outputs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb1-11">input_rate <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span> <span class="co" style="color: #5E5E5E;">#Hz</span></span>
<span id="cb1-12">weights <span class="op" style="color: #5E5E5E;">=</span> np.random.randn(nb_outputs, nb_inputs)<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">0.5</span><span class="op" style="color: #5E5E5E;">+</span><span class="fl" style="color: #AD0000;">0.1</span></span>
<span id="cb1-13">dts <span class="op" style="color: #5E5E5E;">=</span> np.logspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">10</span>) <span class="co" style="color: #5E5E5E;"># in seconds</span></span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;"># Simulation</span></span>
<span id="cb1-16">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">4</span>), tight_layout<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-17">spike_rates <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="bu" style="color: null;">len</span>(dts), nb_outputs)) <span class="co" style="color: #5E5E5E;"># output</span></span>
<span id="cb1-18"><span class="cf" style="color: #003B4F;">for</span> i, dt <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(dts):</span>
<span id="cb1-19">    time <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">0</span>, duration, dt)</span>
<span id="cb1-20">    u <span class="op" style="color: #5E5E5E;">=</span> np.zeros(nb_outputs)</span>
<span id="cb1-21">    _exp <span class="op" style="color: #5E5E5E;">=</span> np.exp(<span class="op" style="color: #5E5E5E;">-</span>dt<span class="op" style="color: #5E5E5E;">/</span>tau)</span>
<span id="cb1-22">    input_spikes <span class="op" style="color: #5E5E5E;">=</span> np.random.poisson(lam<span class="op" style="color: #5E5E5E;">=</span>input_rate<span class="op" style="color: #5E5E5E;">*</span>dt, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="bu" style="color: null;">len</span>(time), nb_inputs))</span>
<span id="cb1-23">    weighted_input_spikes <span class="op" style="color: #5E5E5E;">=</span> input_spikes <span class="op" style="color: #5E5E5E;">@</span> weights.T</span>
<span id="cb1-24">    spike_count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb1-25"></span>
<span id="cb1-26">    <span class="cf" style="color: #003B4F;">for</span> j, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(time):</span>
<span id="cb1-27">        u <span class="op" style="color: #5E5E5E;">=</span> _exp <span class="op" style="color: #5E5E5E;">*</span> u <span class="op" style="color: #5E5E5E;">+</span> weighted_input_spikes[j]</span>
<span id="cb1-28">        spikes <span class="op" style="color: #5E5E5E;">=</span> u <span class="op" style="color: #5E5E5E;">&gt;</span> thresh</span>
<span id="cb1-29">        spike_count <span class="op" style="color: #5E5E5E;">+=</span> spikes</span>
<span id="cb1-30">        u[spikes] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span> <span class="co" style="color: #5E5E5E;"># reset</span></span>
<span id="cb1-31">    spike_rates[i] <span class="op" style="color: #5E5E5E;">+=</span> spike_count <span class="op" style="color: #5E5E5E;">/</span> duration</span>
<span id="cb1-32">ax.errorbar(dts<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">1000</span>, spike_rates.mean(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), yerr<span class="op" style="color: #5E5E5E;">=</span>spike_rates.std(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), capsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>,)</span>
<span id="cb1-33">ax.set_xscale(<span class="st" style="color: #20794D;">"log"</span>)</span>
<span id="cb1-34">ax.set_xlabel(<span class="st" style="color: #20794D;">"$</span><span class="ch" style="color: #20794D;">\\</span><span class="st" style="color: #20794D;">delta t$ [ms]"</span>)</span>
<span id="cb1-35">ax.set_ylabel(<span class="st" style="color: #20794D;">"Output firing rate [sp/s]"</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://tihbe.github.io/posts/2023-03-18-dt-vs-lif/index_files/figure-html/cell-2-output-1.png" width="566" height="374"></p>
</div>
</div>
<p>We arrive at a similar-looking plot, where the output spiking frequency is going down near <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t=1"> ms.</p>
</section>
<section id="hypothesis" class="level1">
<h1>Hypothesis</h1>
<p>A lot of commenters of the original thread suggested that <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> must be chosen in accordance to <img src="https://latex.codecogs.com/png.latex?%5Ctau">. Of course, there is some influence of the chosen time constant <img src="https://latex.codecogs.com/png.latex?%5Ctau">, as the smaller the leakage during a timestep, the smaller the error of membrane potential that can happen. Although, I’m not convinced by that idea, because of the random nature of Poisson spikes. If a spike can arrive at any point in time during a timestep, eventually, the overestimation of membrane potential will roughly equal the underestimation. My hypothesis differs. I believe that the key difference is elsewhere. Because of the nature of the simulation, a neuron can only emit a single spike during one timestep. As a result, the LIF neuron is in a sort-of implicit refractory period for the duration of a timestep. Therefore, when the timestep if very large, i.e., <img src="https://latex.codecogs.com/png.latex?%3E1"> ms in this example, the neuron has a large refractory period as well, causing it to miss very important input spikes as it is not integrating new input during this cycle.</p>
<p>If the assumption is correct, i.e the timestep <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> if forcing an implicit refractory period, then having a large refractory period but with a smaller <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> should yield the same result as having a larger <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t">. If we add a refractory period to the experiment above, we’ll see that they do indeed provide a similar effect:</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">4</span>), tight_layout<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="cf" style="color: #003B4F;">for</span> refractory_period <span class="kw" style="color: #003B4F;">in</span> [<span class="fl" style="color: #AD0000;">0.001</span>, <span class="fl" style="color: #AD0000;">0.01</span>, <span class="fl" style="color: #AD0000;">0.1</span>]:</span>
<span id="cb2-4">    spike_rates <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="bu" style="color: null;">len</span>(dts), nb_outputs)) <span class="co" style="color: #5E5E5E;"># output</span></span>
<span id="cb2-5">    <span class="cf" style="color: #003B4F;">for</span> i, dt <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(dts):</span>
<span id="cb2-6">        time <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">0</span>, duration, dt)</span>
<span id="cb2-7">        refrac_clk <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(refractory_period<span class="op" style="color: #5E5E5E;">/</span>dt)</span>
<span id="cb2-8">        u <span class="op" style="color: #5E5E5E;">=</span> np.zeros(nb_outputs)</span>
<span id="cb2-9">        refrac_cntr <span class="op" style="color: #5E5E5E;">=</span> np.zeros(nb_outputs, dtype<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">int</span>)</span>
<span id="cb2-10">        _exp <span class="op" style="color: #5E5E5E;">=</span> np.exp(<span class="op" style="color: #5E5E5E;">-</span>dt<span class="op" style="color: #5E5E5E;">/</span>tau)</span>
<span id="cb2-11">        input_spikes <span class="op" style="color: #5E5E5E;">=</span> np.random.poisson(lam<span class="op" style="color: #5E5E5E;">=</span>input_rate<span class="op" style="color: #5E5E5E;">*</span>dt, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="bu" style="color: null;">len</span>(time), nb_inputs))</span>
<span id="cb2-12">        weighted_input_spikes <span class="op" style="color: #5E5E5E;">=</span> input_spikes <span class="op" style="color: #5E5E5E;">@</span> weights.T</span>
<span id="cb2-13">        spike_count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb2-14"></span>
<span id="cb2-15">        <span class="cf" style="color: #003B4F;">for</span> j, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(time):</span>
<span id="cb2-16">            non_refrac_neurons <span class="op" style="color: #5E5E5E;">=</span> refrac_cntr<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb2-17">            u[non_refrac_neurons] <span class="op" style="color: #5E5E5E;">=</span> _exp <span class="op" style="color: #5E5E5E;">*</span> u[non_refrac_neurons] <span class="op" style="color: #5E5E5E;">+</span> weighted_input_spikes[j, non_refrac_neurons]</span>
<span id="cb2-18">            spikes <span class="op" style="color: #5E5E5E;">=</span> u <span class="op" style="color: #5E5E5E;">&gt;</span> thresh</span>
<span id="cb2-19">            spike_count <span class="op" style="color: #5E5E5E;">+=</span> spikes</span>
<span id="cb2-20">            u[spikes] <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span> <span class="co" style="color: #5E5E5E;"># reset</span></span>
<span id="cb2-21"></span>
<span id="cb2-22">            <span class="co" style="color: #5E5E5E;"># Setup refractory period</span></span>
<span id="cb2-23">            refrac_cntr <span class="op" style="color: #5E5E5E;">=</span> np.maximum(refrac_cntr<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb2-24">            refrac_cntr[spikes] <span class="op" style="color: #5E5E5E;">+=</span> refrac_clk</span>
<span id="cb2-25"></span>
<span id="cb2-26">        spike_rates[i] <span class="op" style="color: #5E5E5E;">+=</span> spike_count <span class="op" style="color: #5E5E5E;">/</span> duration</span>
<span id="cb2-27"></span>
<span id="cb2-28"></span>
<span id="cb2-29">    ax.errorbar(dts<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">1000</span>, spike_rates.mean(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), yerr<span class="op" style="color: #5E5E5E;">=</span>spike_rates.std(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), capsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"Refrac.: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="dv" style="color: #AD0000;">1000</span><span class="op" style="color: #5E5E5E;">*</span>refractory_period<span class="sc" style="color: #5E5E5E;">:0.1f}</span><span class="ss" style="color: #20794D;">ms"</span>)</span>
<span id="cb2-30">    ax.set_xscale(<span class="st" style="color: #20794D;">"log"</span>)</span>
<span id="cb2-31">    ax.set_xlabel(<span class="st" style="color: #20794D;">"$</span><span class="ch" style="color: #20794D;">\\</span><span class="st" style="color: #20794D;">delta t$ [ms]"</span>)</span>
<span id="cb2-32">    ax.set_ylabel(<span class="st" style="color: #20794D;">"Output firing rate [sp/s]"</span>)</span>
<span id="cb2-33">    ax.legend(loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"lower left"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://tihbe.github.io/posts/2023-03-18-dt-vs-lif/index_files/figure-html/cell-3-output-1.png" width="566" height="374"></p>
</div>
</div>
<p>As we see, the output firing rates align when <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> is equal to the refractory period. For example, at <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t=10"> ms, the orange line only starts going down when the timestep becomes bigger than the explicit refractory period. Therefore, the model is actually correct. The only difference is that we have to consider that the effective refractory period is equal to the maximum between <img src="https://latex.codecogs.com/png.latex?%5Cdelta%20t"> and the explicit refractory period.</p>
</section>
<section id="solution" class="level1">
<h1>Solution</h1>
<p>The solution to this problem is quite simple. As I said before, the timestep of the simulation forces an implicit refractory period because the neuron can only spike once per timstep. If we remove this limitation, then we should remove this implicit refractory period and the output firing rate should be constant regardless of the timestep.</p>
<p>To do so, we count the number of times the membrane potential <img src="https://latex.codecogs.com/png.latex?u(t)"> is above the threshold to estimate how many times the neuron would spike in one timestep. <img src="https://latex.codecogs.com/png.latex?n_%7Bspikes%7D(t)=%5Clfloor%20%5Cfrac%7B%5Cmax%20%5C%7Bu(t),%200%5C%7D%7D%7Bu_%7Bthresh%7D%7D%20%5Crfloor">. We also edit the reset, such that we remove the threshold from the membrane potential <img src="https://latex.codecogs.com/png.latex?n_%7Bspikes%7D"> times, refered to as a soft-reset. This reset mechanism is more precise when dealing with large timesteps, as the accumulated membrane potential is not wasted by an early spike during a timestep. We re-simulate the first experiment with this modification, and we obtain:</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1">np.random.seed(<span class="bn" style="color: #AD0000;">0x1B</span>)</span>
<span id="cb3-2">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">4</span>), tight_layout<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-3">spike_rates <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="bu" style="color: null;">len</span>(dts), nb_outputs)) <span class="co" style="color: #5E5E5E;"># output</span></span>
<span id="cb3-4"><span class="cf" style="color: #003B4F;">for</span> i, dt <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(dts):</span>
<span id="cb3-5">    time <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">0</span>, duration, dt)</span>
<span id="cb3-6">    u <span class="op" style="color: #5E5E5E;">=</span> np.zeros(nb_outputs)</span>
<span id="cb3-7">    _exp <span class="op" style="color: #5E5E5E;">=</span> np.exp(<span class="op" style="color: #5E5E5E;">-</span>dt<span class="op" style="color: #5E5E5E;">/</span>tau)</span>
<span id="cb3-8">    input_spikes <span class="op" style="color: #5E5E5E;">=</span> np.random.poisson(lam<span class="op" style="color: #5E5E5E;">=</span>input_rate<span class="op" style="color: #5E5E5E;">*</span>dt, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="bu" style="color: null;">len</span>(time), nb_inputs))</span>
<span id="cb3-9">    weighted_input_spikes <span class="op" style="color: #5E5E5E;">=</span> input_spikes <span class="op" style="color: #5E5E5E;">@</span> weights.T</span>
<span id="cb3-10">    spike_count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb3-11"></span>
<span id="cb3-12">    <span class="cf" style="color: #003B4F;">for</span> j, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(time):</span>
<span id="cb3-13">        u <span class="op" style="color: #5E5E5E;">=</span> _exp <span class="op" style="color: #5E5E5E;">*</span> u <span class="op" style="color: #5E5E5E;">+</span> weighted_input_spikes[j]</span>
<span id="cb3-14">        <span class="co" style="color: #5E5E5E;">#previous code: spikes = u &gt; thresh</span></span>
<span id="cb3-15">        spikes <span class="op" style="color: #5E5E5E;">=</span> np.floor(np.maximum(u, <span class="dv" style="color: #AD0000;">0</span>) <span class="op" style="color: #5E5E5E;">/</span> thresh) <span class="co" style="color: #5E5E5E;"># multiple spikes</span></span>
<span id="cb3-16">        spike_count <span class="op" style="color: #5E5E5E;">+=</span> spikes</span>
<span id="cb3-17">        u <span class="op" style="color: #5E5E5E;">-=</span> spikes<span class="op" style="color: #5E5E5E;">*</span>thresh</span>
<span id="cb3-18">        <span class="co" style="color: #5E5E5E;">#u[spikes &gt; 0] = 0 </span></span>
<span id="cb3-19"></span>
<span id="cb3-20">    spike_rates[i] <span class="op" style="color: #5E5E5E;">+=</span> spike_count <span class="op" style="color: #5E5E5E;">/</span> duration</span>
<span id="cb3-21">ax.errorbar(dts<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">1000</span>, spike_rates.mean(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), yerr<span class="op" style="color: #5E5E5E;">=</span>spike_rates.std(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>), capsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>,)</span>
<span id="cb3-22">ax.set_xscale(<span class="st" style="color: #20794D;">"log"</span>)</span>
<span id="cb3-23">ax.set_xlabel(<span class="st" style="color: #20794D;">"$</span><span class="ch" style="color: #20794D;">\\</span><span class="st" style="color: #20794D;">delta t$ [ms]"</span>)</span>
<span id="cb3-24">ax.set_ylabel(<span class="st" style="color: #20794D;">"Output firing rate [sp/s]"</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://tihbe.github.io/posts/2023-03-18-dt-vs-lif/index_files/figure-html/cell-4-output-1.png" width="566" height="374"></p>
</div>
</div>
<p>And voilà! We get the expected firing rate across all the timesteps. While this solution is very interesting for computational neuroscientists, it partly removes the energy-friendly ness of spiking neural networks since they are not binary anymore, and the reset involves some arithmetic.</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{balafrej2023,
  author = {Ismael Balafrej},
  title = {Selection of a Timestep for {SNN} Simulation},
  date = {2023-03-19},
  url = {https://tihbe.github.io//posts/2023-03-18-dt-vs-lif},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-balafrej2023" class="csl-entry quarto-appendix-citeas">
Ismael Balafrej. 2023. <span>“Selection of a Timestep for SNN
Simulation.”</span> March 19, 2023. <a href="https://tihbe.github.io//posts/2023-03-18-dt-vs-lif">https://tihbe.github.io//posts/2023-03-18-dt-vs-lif</a>.
</div></div></section></div> ]]></description>
  <category>SNN</category>
  <category>LIF</category>
  <guid>https://tihbe.github.io/posts/2023-03-18-dt-vs-lif/index.html</guid>
  <pubDate>Sun, 19 Mar 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
